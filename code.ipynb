{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils import plot_model\n",
    "import os,math,random,cv2\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "import keras\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451\n",
      "330\n",
      "244\n",
      "291\n",
      "162\n",
      "444\n",
      "491\n",
      "540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bed', 'lamp', 'wardrobe', 'stool', 'shelf', 'chair', 'table', 'sofa']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_train_test(percent=0.8):\n",
    "    categories=[f for f in os.listdir('data') if not f.startswith('.')]\n",
    "    for c in categories:\n",
    "        allImages=[f for f in os.listdir('data/'+c) if f.endswith('.jpg') and not f.startswith('.')]\n",
    "        totalImages=int(len(allImages))\n",
    "        train_size=int(math.ceil(totalImages*percent))\n",
    "        test_size=totalImages-train_size\n",
    "        random.shuffle(allImages)\n",
    "        train_images=allImages[:train_size]\n",
    "        test_images=[item for item in allImages if item not in train_images]\n",
    "        if not os.path.exists('./data/'+c+'/train'):\n",
    "            os.makedirs('./data/'+c+'/train')\n",
    "        if not os.path.exists('./data/'+c+'/test'):\n",
    "            os.makedirs('./data/'+c+'/test')\n",
    "        print(c+\":\"+len(train_images))\n",
    "        for i in train_images:\n",
    "            os.rename('./data/'+c+'/'+i,'./data/'+c+'/train'+'/'+i)\n",
    "        for i in test_images:\n",
    "            os.rename(\"./data/\"+c+'/'+i,\"./data/\"+c+'/test'+'/'+i)\n",
    "    return categories    \n",
    "\n",
    "split_train_test()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=[f for f in os.listdir('data') if not f.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCategory(n):\n",
    "    return categories[n]\n",
    "def returnCatPos(x):\n",
    "    return categories.index(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading : bed\n",
      "Loading : lamp\n",
      "Loading : wardrobe\n",
      "Loading : stool\n",
      "Loading : shelf\n",
      "Loading : chair\n",
      "Loading : table\n",
      "Loading : sofa\n"
     ]
    }
   ],
   "source": [
    "def load_data(resize_dim):\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    X_test=[]\n",
    "    Y_test=[]\n",
    "    for c in categories:\n",
    "        print(\"Loading : \"+c)\n",
    "        train_folder='./data/'+c+'/train/'\n",
    "        test_folder='./data/'+c+'/test/'\n",
    "        for i in os.listdir(train_folder):            \n",
    "            my_image=cv2.imread(train_folder+i)\n",
    "            resized_image = cv2.resize(my_image, (resize_dim, resize_dim)) \n",
    "            X_train.append((resized_image))\n",
    "            Y_train.append(returnCatPos(c))\n",
    "            \n",
    "        for i in os.listdir(test_folder):            \n",
    "            my_image=cv2.imread(test_folder+i)\n",
    "            resized_image = cv2.resize(my_image, (resize_dim, resize_dim)) \n",
    "            X_test.append((resized_image))\n",
    "            Y_test.append(returnCatPos(c)) \n",
    "    X_train=np.asarray(X_train)\n",
    "    Y_train=np.asarray(Y_train)\n",
    "    X_test=np.asarray(X_test)\n",
    "    Y_test=np.asarray(Y_test)\n",
    "    return X_train,Y_train,X_test,Y_test\n",
    "X_train,Y_train,X_test,Y_test=load_data(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(733,)\n",
      "(2953, 8)\n"
     ]
    }
   ],
   "source": [
    "#Encode Y to one-hot\n",
    "def encode_y():\n",
    "    b = np.zeros((len(Y_train), 8))\n",
    "    b[np.arange(len(Y_train)), Y_train] = 1\n",
    "    Y_train_enc=b\n",
    "\n",
    "    c = np.zeros((len(Y_test), 8))\n",
    "    c[np.arange(len(Y_test)), Y_test] = 1\n",
    "    Y_test_enc=b\n",
    "    print(Y_test.shape)\n",
    "encode_y()\n",
    "print(Y_train_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples = 2953\n",
      "Number of testing samples = 733\n",
      "Image dimension = (128, 128, 3)\n",
      "(2953,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples =\",X_train.shape[0])\n",
    "print(\"Number of testing samples =\",X_test.shape[0])\n",
    "print(\"Image dimension =\",X_train.shape[1:])\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# samples_per_epoch = 1000\n",
    "# nb_filters1 = 32\n",
    "# nb_filters2 = 64\n",
    "# conv1_size = 3\n",
    "# conv2_size = 2\n",
    "# pool_size = 2\n",
    "# classes_num = 8\n",
    "# lr = 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Convolution2D(nb_filters1, conv1_size, conv1_size, border_mode =\"same\", input_shape=(64, 64, 3)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "# model.add(Convolution2D(nb_filters2, conv2_size, conv2_size, border_mode =\"same\"))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D(pool_size=(pool_size, pool_size), dim_ordering='th'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(classes_num, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=optimizers.RMSprop(lr=lr),\n",
    "# metrics=['accuracy'])\n",
    "# # model.fit_generator(\n",
    "# #     train_generator,\n",
    "# #     samples_per_epoch=samples_per_epoch,\n",
    "# #     epochs=epochs,\n",
    "# #     validation_data=validation_generator,\n",
    "# #     callbacks=cbks,\n",
    "# #     validation_steps=validation_steps)\n",
    "\n",
    "# # target_dir = './models/'\n",
    "# # if not os.path.exists(target_dir):\n",
    "# #   os.mkdir(target_dir)\n",
    "# # model.save('./models/model.h5')\n",
    "# # model.save_weights('./models/weights.h5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 58, 58, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1000)              53825000  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 8008      \n",
      "=================================================================\n",
      "Total params: 53,886,704\n",
      "Trainable params: 53,886,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2953/2953 [==============================] - 182s 62ms/step - loss: 13.0376 - acc: 0.1863\n",
      "Epoch 2/10\n",
      "2953/2953 [==============================] - 192s 65ms/step - loss: 12.8261 - acc: 0.1991\n",
      "Epoch 3/10\n",
      "2953/2953 [==============================] - 208s 70ms/step - loss: 11.7655 - acc: 0.2648\n",
      "Epoch 4/10\n",
      "2953/2953 [==============================] - 207s 70ms/step - loss: 10.9550 - acc: 0.3149\n",
      "Epoch 5/10\n",
      "2953/2953 [==============================] - 187s 63ms/step - loss: 9.8896 - acc: 0.3786\n",
      "Epoch 6/10\n",
      "2953/2953 [==============================] - 194s 66ms/step - loss: 9.3106 - acc: 0.4101\n",
      "Epoch 7/10\n",
      "2953/2953 [==============================] - 199s 67ms/step - loss: 4.6355 - acc: 0.6041\n",
      "Epoch 8/10\n",
      "2953/2953 [==============================] - 188s 64ms/step - loss: 1.5071 - acc: 0.7701\n",
      "Epoch 9/10\n",
      "2953/2953 [==============================] - 191s 65ms/step - loss: 0.7612 - acc: 0.8500\n",
      "Epoch 10/10\n",
      "2953/2953 [==============================] - 210s 71ms/step - loss: 0.4170 - acc: 0.9221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b1bb5a2e8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=Y_train_enc,batch_size=32,epochs=10,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
